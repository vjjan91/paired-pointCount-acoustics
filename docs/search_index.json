[["index.html", "Source code and supporting information for Predicting bird species abundances from acoustic data Section 1 Introduction 1.1 Attribution 1.2 Data access 1.3 Data processing", " Source code and supporting information for Predicting bird species abundances from acoustic data Vijay Ramesh Divya Mudappa T R Shankar Raman Laurel B Symes Last compiled on 22 May, 2025 Section 1 Introduction This is the readable version that showcases analyses comparing point count data and acoustic data for a tropical bird community in the Western Ghats. 1.1 Attribution Please contact the following in case of interest in the project. Vijay Ramesh (repo maintainer) Postdoctoral Research Associate, Cornell Lab of Ornithology 1.2 Data access The data used in this work will be archived on Zenodo. 1.3 Data processing The data processing for this project is described in the following sections. Navigate through them using the links in the sidebar. "],["exploring-point-count-data.html", "Section 2 Exploring point-count data 2.1 Loading point-count data 2.2 Load site level information and create gridded data 2.3 Extract species-level information 2.4 Visualizing richness data across seasons 2.5 Visualizing abundance by species across seasons", " Section 2 Exploring point-count data In this script, we will explore the point-count data to understand bird species diversity patterns across seasons. For this analysis, we rely on two seasons of point-count data, that was carried out in June 2024 and Dec 2024. ## Install required libraries library(tidyverse) library(dplyr) library(stringr) library(ggplot2) library(data.table) library(extrafont) library(sf) library(raster) # for plotting library(scales) library(ggplot2) library(ggspatial) library(colorspace) library(scico) # Source any custom/other internal functions necessary for analysis source(&quot;code/01_internal-functions.R&quot;) 2.1 Loading point-count data # load two seasons of point-count data point_counts &lt;- read.csv(&quot;data/point-count-data.csv&quot;) # removing all mammal species and unidentified bird species point_counts &lt;- point_counts %&gt;% filter(birdMamm == &quot;Bird&quot;) # Using gsub to remove text within parentheses including the parentheses point_counts$eBirdIndiaName2023 &lt;- gsub(&quot;\\\\s*\\\\([^\\\\)]+\\\\)&quot;, &quot;&quot;, point_counts$eBirdIndiaName2023) # add species scientific name to the point-count data sci_name &lt;- read.csv(&quot;data/species-taxonomy.csv&quot;) sci_name$eBirdIndiaName2023 &lt;- gsub(&quot;\\\\s*\\\\([^\\\\)]+\\\\)&quot;, &quot;&quot;, sci_name$eBirdIndiaName2023) # add scientific_name to the point_count data point_counts &lt;- left_join(point_counts[,-7], sci_name[,-c(1,2,4)]) # rename columns names(point_counts)[4] &lt;- &quot;start_time&quot; names(point_counts)[7] &lt;- &quot;common_name&quot; names(point_counts)[12] &lt;- &quot;scientific_name&quot; # write to file write.csv(point_counts, &quot;results/cleaned-point-count-data.csv&quot;, row.names = F) 2.2 Load site level information and create gridded data # we write a function below to create a grid around the centroid of each location of size 1ha # the grid is primarily created for visualizing species richness &amp; other associated metrics (this step is optional) # function to create square grid around a point create_square_grid &lt;- function(lon, lat, size_ha = 1) { # convert hectares to degrees (approximate conversion) # 1 ha = 100m x 100m # at the equator, 1 degree is approximately 111,320 meters # so we need to convert 100m to degrees size_degrees &lt;- sqrt(size_ha) * 100 / 111320 # Create a square polygon coords &lt;- matrix(c( lon - size_degrees/2, lat - size_degrees/2, # bottom left lon + size_degrees/2, lat - size_degrees/2, # bottom right lon + size_degrees/2, lat + size_degrees/2, # top right lon - size_degrees/2, lat + size_degrees/2, # top left lon - size_degrees/2, lat - size_degrees/2 # close the polygon ), ncol = 2, byrow = TRUE) # Create polygon pol &lt;- st_polygon(list(coords)) return(pol) } # function to obtain the latitude and longitude from a .csv file and create an associated shapefile create_grid_shapefile &lt;- function(csv_path, output_shp, lon_col = &quot;longitude&quot;, lat_col = &quot;latitude&quot;) { # read CSV file data &lt;- read.csv(csv_path) # create list to store polygons polygons &lt;- list() # create square grid for each point for(i in 1:nrow(data)) { polygons[[i]] &lt;- create_square_grid( data[[lon_col]][i], data[[lat_col]][i] ) } # convert to sf object grid_sf &lt;- st_sf( # Include original data data, # Convert polygon list to geometry geometry = st_sfc(polygons, crs = 4326) ) # write to shapefile st_write(grid_sf, output_shp, driver = &quot;ESRI Shapefile&quot;, append = FALSE) return(grid_sf) } # site-level information sites &lt;- &quot;data/sites.csv&quot; grid_shp &lt;- &quot;data/candura_grids.shp&quot; # Create the grid shapefile grid_sf &lt;- create_grid_shapefile( csv_path = sites, output_shp = grid_shp, lon_col = &quot;decimalLongitude&quot;, # replace with your longitude column name lat_col = &quot;decimalLatitude&quot; # replace with your latitude column name ) 2.3 Extract species-level information # estimate abundance across all species for each grid and season abundance &lt;- point_counts %&gt;% group_by(gridID, common_name, seasonYear) %&gt;% summarise(abundance = sum(number)) %&gt;% ungroup() # unique species observed across seasons # in summer 82 unique species were detected summer_species &lt;- abundance %&gt;% filter(seasonYear == &quot;2024 Summer&quot;) %&gt;% distinct(common_name) # 89 unique species were detected in the winter winter_species &lt;- abundance %&gt;% filter(seasonYear == &quot;2024 Winter&quot;) %&gt;% distinct(common_name) # overall list of unique species detected in point counts # 107 unique species were detected across both seasons pc_species &lt;- abundance %&gt;% group_by(common_name) %&gt;% summarise(cumulative_abundance = sum(abundance)) %&gt;% left_join(., sci_name[,-c(1,2,4)], by = c(&quot;common_name&quot; = &quot;eBirdIndiaName2023&quot;)) %&gt;% rename(., scientific_name = eBirdScientificName2023) %&gt;% arrange(desc(cumulative_abundance)) # write to file write.csv(pc_species, &quot;results/species-in-point-counts.csv&quot;, row.names = F) # total abundance by species for each season across grids totAbundance_by_season &lt;- abundance %&gt;% group_by(common_name, seasonYear) %&gt;% summarise(totAbundance = sum(abundance)) # species most abundant across seasons include the Yellow-browed Bulbul, Southern Hill Myna, Crimson-backed Sunbird, Greater Racket-tailed Drongo # estimate richness for point count data (calculated for each site) richness &lt;- abundance %&gt;% mutate(forRichness = case_when(abundance &gt; 0 ~ 1)) %&gt;% group_by(gridID, seasonYear) %&gt;% summarise(richness = sum(forRichness)) %&gt;% ungroup() 2.4 Visualizing richness data across seasons # First, join your species data with the spatial data grid_with_richness &lt;- grid_sf %&gt;% left_join(richness, by = &quot;gridID&quot;) # Create the plot fig_richness_by_season &lt;- ggplot() + geom_sf(data = grid_with_richness, aes(fill = richness), alpha=0.9) + geom_sf_text(data = grid_with_richness, aes(label = paste(gridID, &quot;\\n&quot;, richness)), size = 2) + facet_wrap(~seasonYear) + scale_fill_scico(palette = &quot;lajolla&quot;)+ theme_minimal() + labs(fill = &quot;Species\\nRichness&quot;, title = &quot;Species Richness by Season&quot;) + theme(text = element_text(family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot;),plot.title = element_text(family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot;), plot.subtitle = element_text(family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot;,color=&quot;#1b2838&quot;), axis.title = element_blank()) ggsave(&quot;figs/fig_richness_by_season.png&quot;, plot = fig_richness_by_season, width = 14, height = 7, units = &quot;in&quot;, dpi = 300, bg = &quot;white&quot;) dev.off() Species richness by season 2.5 Visualizing abundance by species across seasons # join abundance data with the spatial data grid_with_abundance &lt;- grid_sf %&gt;% left_join(abundance, by = &quot;gridID&quot;) # first, let&#39;s create a base grid that has all possible combinations base_grid &lt;- grid_with_abundance %&gt;% dplyr::select(gridID, geometry) %&gt;% distinct() # get unique seasons seasons &lt;- unique(grid_with_abundance$seasonYear) # create a complete grid with all combinations complete_grid &lt;- base_grid %&gt;% crossing(seasonYear = seasons) %&gt;% st_sf() # get unique species list species_list &lt;- unique(grid_with_abundance$common_name) # create PDF pdf(&quot;figs/species_by_season_abundance.pdf&quot;, width = 14, height = 7) # loop through each species for(sp in species_list) { # get data for this species current_species_data &lt;- grid_with_abundance %&gt;% filter(common_name == sp) %&gt;% dplyr::select(gridID, seasonYear, abundance) %&gt;% st_drop_geometry() # join with complete grid plot_data &lt;- complete_grid %&gt;% left_join(current_species_data, by = c(&quot;gridID&quot;, &quot;seasonYear&quot;)) # Create plot p &lt;- ggplot() + geom_sf(data = plot_data, aes(fill = abundance), alpha = 0.9) + geom_sf_text(data = plot_data, aes(label = paste(gridID, &quot;\\n&quot;, ifelse(is.na(abundance), &quot;0&quot;, abundance))), size = 2) + facet_wrap(~seasonYear) + scale_fill_scico(palette = &quot;lajolla&quot;, na.value = &quot;grey80&quot;)+ theme_minimal() + theme(text = element_text(family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot;),plot.title = element_text(family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot;), plot.subtitle = element_text(family = &quot;Century Gothic&quot;, size = 14, face = &quot;bold&quot;,color=&quot;#1b2838&quot;), axis.title = element_blank()) + labs(fill = &quot;Abundance&quot;, title = paste(&quot;Abundance of&quot;, sp, &quot;by Season&quot;)) print(p) } dev.off() "],["exploring-outputs-from-birdnet.html", "Section 3 Exploring outputs from BirdNET 3.1 Install required libraries 3.2 Creating a custom species list for BirdNET analysis 3.3 Results from validating the BirdNET out-of-the-box model 3.4 Setting thresholds for species after validation", " Section 3 Exploring outputs from BirdNET Given our list of species that were detected in the point count data, we carry out the following next steps to achieve automated identification of bird species from the acoustic data. Please visit the acoustic-data-cleaning-procedures.txt to learn more about how the audio data was cleaned prior and processed. 3.1 Install required libraries library(tidyverse) library(dplyr) library(stringr) library(ggplot2) library(data.table) library(extrafont) library(sf) library(raster) library(viridis) # for colorblind-friendly colors library(gridExtra) # for arranging multiple plots # for plotting library(scales) library(ggplot2) library(ggspatial) library(colorspace) library(scico) # Source any custom/other internal functions necessary for analysis source(&quot;code/01_internal-functions.R&quot;) We will carry out a few iterations of the BirdNET analysis to essentially test and improve the detections of multiple species that were detected in our point counts. We first ran a model by using the ‘Batch Analysis’ Tab using the ‘species-by-location’ feature, which essentially runs the out-of-the-box model for species that can potentially occur at that location. However, upon further running the segments.py function through the ‘Segments’ tab, we realized that several species that are present in the point-count data were not captured and several other new species that do not occur have been introduced. We will now run a second model by continuing to test BirdNET’s out-of-the-box model on a custom list of species that we provide to the model. All instructions for running BirdNET were through this document - https://zenodo.org/records/8415090 and conversations with Dr. Laurel Symes and other staff at the K. Lisa Yang Center for Conservation Bioacoustics. 3.2 Creating a custom species list for BirdNET analysis # load the list of species in the point-count data and create a separate file in the format requested by BirdNET # given taxonomic changes in the eBird India list of species, we need to match it with the existing taxonomy provided by BirdNET # list of species in point counts pc_species &lt;- read.csv(&quot;results/species-in-point-counts.csv&quot;) birdNET_species &lt;- read.csv(&quot;data/birdNET-base-model-complete-species-list.csv&quot;) # we join the two columns and create a new column in the format requested by BirdNET custom_list &lt;- left_join(pc_species, birdNET_species, by = c(&quot;common_name&quot; = &quot;common_name_birdNET&quot;) ) %&gt;% mutate(combined_name = paste(scientific_name_birdNET, common_name, sep = &quot;_&quot; )) # Upon creating a combined_name column that includes the scientific_name and common_name in the format requested by BirdNET, we noticed that taxonomic updates in the eBird India file does not match the existing taxonomy as used by BirdNET. # We will save the above file and manually make changes to the same before using it within the BirdNET GUI # We will convert the below file to a text file before running BirdNET write.csv(custom_list, &quot;results/custom-list-for-BirdNET.csv&quot;, row.names = F) Based on the above comparison between what exists in the BirdNET out-of-the-box model and the updated taxonomy, the only species that was detected in the point-count data and is not present in the BirdNET out-of-the-box model is the Indian Swiftlet. Other species had minor taxonomic changes which were not accommodated in the current version and was fixed manually in the text file. 3.3 Results from validating the BirdNET out-of-the-box model Of the list of 106 species (out of a total of 107 that was detected in the point count data) that was provided as a custom list to the BirdNET GUI, only 84 species were detected by BirdNET, from which segments were created (using the segments.py command). We validated the same using Raven Pro for a set of hundred random selections across the range of confidence scores for each species. Species that can be excluded since they are often not detected within the rainforest grids and will not be the focus for our next set of analysis include: Ashy Prinia Brown Boobook (also performed poorly) Brown Fish-Owl Common Sandpiper Oriental-Magpie Robin (few detections) Purple Sunbird Red-rumped Swallow (very few detections) Streak-throated Woodpecker Species for which the model performed poorly and requires a custom classifier include: Black-hooded Oriole Bronzed Drongo (very tricky to validate unless it’s making a chip-oo-yeee call or its repetitive enough that you can distinguish it from the racket-tailed drongo) Brown-breasted Flycatcher Changeable-Hawk Eagle (need to increase segment length to validate better, but often is confused with Crested serpent eagle) Chestnut-headed bee-eater (need to choose a higher confidence score to validate selections in the first place and the model confuses calls with background noise quite a bit/insect vocalizations at similar frequencies) Common Flameback (hard to validate at low confidence scores as the thin-ness of the call is not apparent and easily confused with Malabar/Greater Flameback) Common Iora (a single detection was made and potentially needs a new classifier) Brown Boobook Brown Fish-Owl Crested Goshawk Golden-fronted Leafbird (mimic whose vocalizations at low confidence scores sound very much like the Bronzed Drongo) Black-naped Monarch (either confused with paradise flycatcher - the call and the song is similarly confused with a yellow-browed bulbul potentially) Greater Coucal (confused as Nilgiri Langur) Heart-spotted Woodpecker (confused with other flamebacks and nuthatches) Indian Blue Robin Indian Golden Oriole Indian Pitta Indian Yellow Tit Lesser Yellownape (might as well throw in a random species since the model is picking everything except this species) Malabar Starling Nilgiri Flycatcher (very few detections) Orange-headed Thrush (seems to be confused with hill myna or yellow-browed bulbul) Red Spurfowl Rufous Babbler (very few detections perhaps?) Rusty-tailed Flycatcher (of the few detections, all are accurate but a custom classifier is required) Shikra (few detections at the moment) Verditer Flycatcher (very few detections) White-bellied Woodpecker (almost no detections) Species for which the out-of-the-box model performed well and we could potentially set a threshold include: Asian Fairy-bluebird Brown-capped Pygmy Woodpecker Common Kingfisher Common Tailorbird Crested-Serpent Eagle Crimson-backed Sunbird Eurasian Hoopoe Great Hornbill Greater Flameback (performs pretty well, hard to validate though due to similarity with Common flameback) Indian Peafowl Indian Scimitar-Babbler Indian White-eye Jungle Myna (few detections however) Large-billed Crow Large-billed Leaf Warbler Malabar Barbet Malabar Parakeet Malabar Trogon Malabar Woodshrike Nilgiri Flowerpecker Orange Minivet Red-wattled Lapwing Red-whiskered Bulbul Southern Hill Myna Square-tailed Bulbul Stork-billed Kingfisher White-cheeked Barbet White-throated Kingfisher Yellow-browed Bulbul 3.4 Setting thresholds for species after validation The above notes were made while validating data using Raven Pro. We will now set thresholds for all the species that were validated from the list of 84 species. Below, the code is written in such a way that we are able to handle failure of model fit, convergence and summarize species that have very few detections. We initially set thresholds for the confidence scores at which the probability of a true positive is at 0.90, 0.95 and 0.99. Ultimately, we want to select species for which the model performance is sufficiently high for us to retrieve true positives with a probability of occurrence at 0.95. # create empty dataframes to store results threshold_df &lt;- data.frame( species = character(), threshold90 = numeric(), threshold95 = numeric(), threshold99 = numeric(), n_samples = numeric(), stringsAsFactors = FALSE ) # create dataframe for failed model fits failed_models_df &lt;- data.frame( species = character(), reason = character(), stringsAsFactors = FALSE ) # create dataframe for imbalanced cases imbalanced_df &lt;- data.frame( species = character(), total_samples = numeric(), number_valid_0 = numeric(), number_valid_1 = numeric(), proportion_valid = numeric(), stringsAsFactors = FALSE ) # create dataframe for all excluded species excluded_species_df &lt;- data.frame( species = character(), reason = character(), details = character(), stringsAsFactors = FALSE ) # create list to store plots plot_list &lt;- list() # get list of species folders species_folders &lt;- list.dirs(&quot;results/birdNET-segments&quot;, full.names = TRUE, recursive = FALSE) # get all species folders names all_species &lt;- basename(species_folders) # loop through each species folder for (folder in species_folders) { species_name &lt;- basename(folder) # find the .txt file file_path &lt;- list.files(folder, pattern = &quot;.txt$&quot;, full.names = TRUE) # handling missing .txt files for species if (length(file_path) == 0) { excluded_species_df &lt;- rbind( excluded_species_df, data.frame( species = species_name, reason = &quot;missing_file&quot;, details = &quot;No .txt file found&quot; ) ) next } # read the data table &lt;- read.table(file_path, sep = &quot;\\t&quot;, header = TRUE) # filter for Spectrogram 1 # there are duplicates in the selection table at times table &lt;- table %&gt;% filter(View == &quot;Spectrogram 1&quot;) # extract score table$Score &lt;- as.numeric(substr(table$Begin.File, 1, 5)) # check for NAs in Valid if (any(is.na(table$Valid))) { excluded_species_df &lt;- rbind( excluded_species_df, data.frame( species = species_name, reason = &quot;invalid_data&quot;, details = &quot;NAs found in Valid column&quot; ) ) next } # check if there are at least 5 rows # remove species with too few samples if (nrow(table) &lt; 5) { excluded_species_df &lt;- rbind( excluded_species_df, data.frame( species = species_name, reason = &quot;insufficient_samples&quot;, details = paste(&quot;Only&quot;, nrow(table), &quot;samples&quot;) ) ) next } # check if there&#39;s enough variation in the Score if (length(unique(table$Score)) &lt; 5) { excluded_species_df &lt;- rbind( excluded_species_df, data.frame( species = species_name, reason = &quot;insufficient_score_variation&quot;, details = paste(&quot;Only&quot;, length(unique(table$Score)), &quot;unique scores&quot;) ) ) next } # check for extreme imbalance in Valid prop_valid &lt;- mean(table$Valid) n_valid_0 &lt;- sum(table$Valid == 0) n_valid_1 &lt;- sum(table$Valid == 1) if (prop_valid &lt; 0.05 || prop_valid &gt; 0.95) { excluded_species_df &lt;- rbind( excluded_species_df, data.frame( species = species_name, reason = &quot;imbalanced_data&quot;, details = paste( &quot;Valid proportion:&quot;, round(prop_valid, 3), &quot;, Valid_0:&quot;, n_valid_0, &quot;, Valid_1:&quot;, n_valid_1 ) ) ) # also add to imbalanced_df imbalanced_df &lt;- rbind( imbalanced_df, data.frame( species = species_name, total_samples = nrow(table), number_valid_0 = n_valid_0, number_valid_1 = n_valid_1, proportion_valid = prop_valid ) ) next } # try to fit the model with tryCatch model_fit &lt;- tryCatch( { model &lt;- glm(Valid ~ Score, family = &quot;binomial&quot;, data = table) # check for convergence if (!model$converged) { excluded_species_df &lt;- rbind( excluded_species_df, data.frame( species = species_name, reason = &quot;model_non_convergence&quot;, details = &quot;Model did not converge&quot; ) ) failed_models_df &lt;- rbind( failed_models_df, data.frame( species = species_name, reason = &quot;model did not converge&quot; ) ) return(NULL) } # calculate predictions prediction.range.conf &lt;- seq(0, 1, .001) predictions.conf &lt;- predict(model, list(Score = prediction.range.conf), type = &quot;r&quot;) # Calculate thresholds threshold90 &lt;- (log(.90 / (1 - .90)) - model$coefficients[1]) / model$coefficients[2] threshold95 &lt;- (log(.95 / (1 - .95)) - model$coefficients[1]) / model$coefficients[2] threshold99 &lt;- (log(.99 / (1 - .99)) - model$coefficients[1]) / model$coefficients[2] # check if thresholds are within reasonable bounds if (any(c(threshold90, threshold95, threshold99) &lt; 0) || any(c(threshold90, threshold95, threshold99) &gt; 1) || any(is.infinite(c(threshold90, threshold95, threshold99))) || any(is.na(c(threshold90, threshold95, threshold99)))) { excluded_species_df &lt;- rbind( excluded_species_df, data.frame( species = species_name, reason = &quot;invalid_thresholds&quot;, details = &quot;Threshold values outside valid range&quot; ) ) failed_models_df &lt;- rbind( failed_models_df, data.frame( species = species_name, reason = &quot;invalid threshold values&quot; ) ) return(NULL) } list( model = model, predictions = predictions.conf, thresholds = c(threshold90, threshold95, threshold99) ) }, error = function(e) { excluded_species_df &lt;- rbind( excluded_species_df, data.frame( species = species_name, reason = &quot;model_error&quot;, details = paste(&quot;Error:&quot;, e$message) ) ) failed_models_df &lt;- rbind( failed_models_df, data.frame( species = species_name, reason = paste(&quot;error:&quot;, e$message) ) ) return(NULL) } ) # skip to next species if model fitting failed if (is.null(model_fit)) { next } # extract results from successful model fit model &lt;- model_fit$model predictions.conf &lt;- model_fit$predictions threshold90 &lt;- model_fit$thresholds[1] threshold95 &lt;- model_fit$thresholds[2] threshold99 &lt;- model_fit$thresholds[3] # store thresholds threshold_df &lt;- rbind( threshold_df, data.frame( species = species_name, threshold90 = threshold90, threshold95 = threshold95, threshold99 = threshold99, n_samples = nrow(table) ) ) # round threshold values to 3 decimal places for labels threshold90_label &lt;- round(threshold90, 3) threshold95_label &lt;- round(threshold95, 3) threshold99_label &lt;- round(threshold99, 3) # get viridis colors viz_colors &lt;- viridis(5) curve_color &lt;- viz_colors[1] threshold_colors &lt;- viz_colors[c(2, 3, 4)] # create ggplot p &lt;- ggplot(table, aes(x = Score, y = Valid)) + geom_point(alpha = 0.2) + geom_line( data = data.frame( x = prediction.range.conf, y = predictions.conf ), aes(x = x, y = y), color = curve_color, size = 1.2 ) + geom_vline(xintercept = threshold90, color = threshold_colors[1], size = 1) + geom_vline(xintercept = threshold95, color = threshold_colors[2], size = 1) + geom_vline(xintercept = threshold99, color = threshold_colors[3], size = 1) + # add threshold labels with offset annotate(&quot;text&quot;, x = pmin(pmax(threshold90, 0.05), 0.95) + 0.02, y = 0.5, label = paste(&quot;90%:&quot;, threshold90_label), color = threshold_colors[1], family = &quot;Century Gothic&quot;, angle = 90, hjust = 0.5, size = 3 ) + annotate(&quot;text&quot;, x = pmin(pmax(threshold95, 0.05), 0.95) + 0.02, y = 0.5, label = paste(&quot;95%:&quot;, threshold95_label), color = threshold_colors[2], family = &quot;Century Gothic&quot;, angle = 90, hjust = 0.5, size = 3 ) + annotate(&quot;text&quot;, x = pmin(pmax(threshold99, 0.05), 0.95) + 0.02, y = 0.5, label = paste(&quot;99%:&quot;, threshold99_label), color = threshold_colors[3], family = &quot;Century Gothic&quot;, angle = 90, hjust = 0.5, size = 3 ) + labs( title = species_name, x = &quot;Confidence Score&quot;, y = &quot;pr(BirdNET prediction is correct)&quot; ) + theme_minimal() + theme( text = element_text(family = &quot;Century Gothic&quot;), plot.title = element_text(family = &quot;Century Gothic&quot;, size = 14), axis.title = element_text(family = &quot;Century Gothic&quot;, size = 12), axis.text = element_text(family = &quot;Century Gothic&quot;, size = 10) ) + scale_x_continuous(limits = c(0, 1)) + scale_y_continuous(limits = c(0, 1)) plot_list[[species_name]] &lt;- p } # get list of species for which plots were successfully made successful_species &lt;- names(plot_list) # find species that weren&#39;t processed at all unprocessed_species &lt;- setdiff( all_species, unique(c( successful_species, excluded_species_df$species )) ) # add unprocessed species to excluded_species_df if any exist if (length(unprocessed_species) &gt; 0) { excluded_species_df &lt;- rbind( excluded_species_df, data.frame( species = unprocessed_species, reason = &quot;unknown&quot;, details = &quot;Species was not processed&quot; ) ) } # write output files write.csv(threshold_df, &quot;results/species_thresholds_outOfTheBox.csv&quot;, row.names = FALSE) write.csv(failed_models_df, &quot;results/failed_models_outOfTheBox.csv&quot;, row.names = FALSE) write.csv(imbalanced_df, &quot;results/imbalanced_cases_outOfTheBox.csv&quot;, row.names = FALSE) write.csv(excluded_species_df, &quot;results/excluded_species_outOfTheBox.csv&quot;, row.names = FALSE) # save all plots to PDF pdf(&quot;figs/species_threshold_outOfTheBox.pdf&quot;, width = 10, height = 8, family = &quot;Century Gothic&quot;) for (p in plot_list) { print(p) } dev.off() # print summary cat(&quot;\\nSummary:\\n&quot;) cat(&quot;Total species:&quot;, length(all_species), &quot;\\n&quot;) cat(&quot;Successful species:&quot;, length(successful_species), &quot;\\n&quot;) cat(&quot;Excluded species:&quot;, nrow(excluded_species_df), &quot;\\n&quot;) cat(&quot;\\nExclusion reasons:\\n&quot;) print(table(excluded_species_df$reason)) Based on the above summary accounting for errors in model convergeneces, missing files, invalid thresholds and imbalanced data, we can safely ignore: species with insufficient samples/detections species that have missing files (in order words, these are essentially species with very few detections that I did not validate them and generate a selection table) The next steps involve: a) examining the species threshold plot for those species for which the logistic regression/binomial glm converged. For such species, we choose the threshold at which species probability of detecting a true positive is 0.95. b) we go through the list of species which are reported as having imbalanced data or invalid thresholds and we set a blanket threshold of 0.25 for such species and include a subset of the same. This would involve qualitative examination of the list of species from the notes made above. This .csv is titled curatedThresholds-species-list.csv, which can be used in future scripts to extract detections from the BirdNET-outputs-folder to generate the paired-acoustic dataset. "],["data-comparability.html", "Section 4 Data comparability 4.1 Install required libraries 4.2 Loading the acoustic data and filtering outputs above a threshold 4.3 Loading point count data 4.4 Curating the acoustic dataset and creating a new object", " Section 4 Data comparability In this script, we extract acoustic detections from each audio file by using the curated thresholds that were set for BirdNET data and compare it with the cleaned point count dataset. 4.1 Install required libraries library(tidyverse) library(dplyr) library(stringr) library(ggplot2) library(data.table) library(extrafont) library(sf) library(raster) # for plotting library(scales) library(ggplot2) library(ggspatial) library(colorspace) library(scico) # Source any custom/other internal functions necessary for analysis source(&quot;code/01_internal-functions.R&quot;) 4.2 Loading the acoustic data and filtering outputs above a threshold In the previous script, we created curated thresholds for each species above which the probability of detecting a species is at 0.95. For a few species for which the detector performed really well (proportion of true positives: false positives &gt; 0.95), we set a random threshold value of 0.25 above which we expect the probability of species detected to be greater than or equal to 0.95. ## curate species thresholds threshold &lt;- read.csv(&quot;results/curatedThresholds-species-list.csv&quot;) ## load the BirdNET output file birdnet_results &lt;- read.csv(&quot;results/birdNET-outputs/BirdNET_CombinedTable.csv&quot;) ## filter species detections above the threshold we chose ## include a gridID column so that we can join this with the point_count data birdnet_subset &lt;- birdnet_results %&gt;% inner_join(threshold, by = c(&quot;Common.name&quot; = &quot;species&quot;)) %&gt;% filter(Confidence &gt;= threshold) %&gt;% mutate(filename_pattern = basename(File) %&gt;% sub(&quot;.*\\\\\\\\([0-9]{8}_[0-9]{4}_[A-Z0-9]+)\\\\.WAV&quot;, &quot;\\\\1&quot;, .)) %&gt;% mutate(date = substr(filename_pattern, 1, 8) %&gt;% ymd() %&gt;% format(&quot;%Y-%b-%d&quot;)) %&gt;% mutate(gridID = substr(filename_pattern, 15, nchar(filename_pattern)) %&gt;% sub(&quot;\\\\.WAV$&quot;, &quot;&quot;, .)) 4.3 Loading point count data point_count &lt;- read.csv(&quot;results/cleaned-point-count-data.csv&quot;) 4.4 Curating the acoustic dataset and creating a new object # use only a subset of the birdnet_subset columns for the new object acoustic_data &lt;- birdnet_subset[,c(3,4,9,10)] names(acoustic_data) &lt;- c(&quot;scientific_name&quot;,&quot;common_name&quot;, &quot;date&quot;, &quot;gridID&quot;) # summarise and group the data based on the four columns and create a number column that indicates the number of acoustic detections acoustic_data &lt;- acoustic_data %&gt;% group_by(scientific_name, common_name, date, gridID) %&gt;% summarise(number = n()) %&gt;% ungroup() # create a new column to indicate dateType acoustic_data &lt;- acoustic_data %&gt;% mutate(dataType = &quot;acoustic_data&quot;) point_count &lt;- point_count %&gt;% mutate(dataType = &quot;point_count&quot;) # join with point_count data (remove the birdMamm column since all the data we are dealing with is bird data) datSubset &lt;- bind_rows(point_count[,-6], acoustic_data) # based on differences in taxonomy updates done by BirdNET and the eBird team and the species that we are currently analyzing, the Greater Flameback needs to be changed to Malabar Flameback along with it&#39;s scientific name # note: VR also had to manually edit the cleaned-point-data.csv to match older scientific names that are currently accepted by BirdNET datSubset &lt;- datSubset %&gt;% mutate( common_name = case_when( common_name == &quot;Greater Flameback&quot; ~ &quot;Malabar Flameback&quot;, TRUE ~ common_name ), scientific_name = case_when( scientific_name == &quot;Chrysocolaptes guttacristatus&quot; ~ &quot;Chrysocolaptes socialis&quot;, TRUE ~ scientific_name ) ) # let&#39;s fill in missing rows for seasonYear and start_time datSubset &lt;- datSubset %&gt;% group_by(date, gridID) %&gt;% # fill(start_time, .direction = &quot;downup&quot;) %&gt;% fill(seasonYear, .direction = &quot;downup&quot;) %&gt;% ungroup() # change structures before writing to file datSubset$start_time &lt;- as.character(datSubset$start_time) datSubset$timeSeg &lt;- as.character(datSubset$timeSeg) # rename columns names(datSubset)[1] &lt;- &quot;year_season&quot; names(datSubset)[5] &lt;- &quot;time_segment&quot; # lastly, before writing the data locally, we only keep those species that are present in the curated birdNet thresholds species list and ignore those found only in point_count data and not in acoustic_data # filter the entire dataframe to keep only those species in the species_thresholds list names(threshold)[1] &lt;- &quot;common_name&quot; threshold &lt;- threshold %&gt;% mutate( common_name = case_when( common_name == &quot;Greater Flameback&quot; ~ &quot;Malabar Flameback&quot;, TRUE ~ common_name )) # filter those species # we only retain 44 species of the initial list of 107 that were detected in point_counts datSubset &lt;- datSubset %&gt;% filter(common_name %in% threshold$common_name) # write to file write.csv(datSubset, &quot;results/datSubset.csv&quot;, row.names = F) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
